```{r echo=FALSE}
library(readr)
library(ggplot2)
library(dplyr)
library(tidymodels)
library(rjson)
library(stringr)
library(broom)
tidymodels_prefer()
```

# load in data
```{r}
stringency_data <- read.csv('covid-stringency-index.csv')
all_data <- read.csv('owid-covid-data.csv')

isl_swe_data <- all_data %>%
  filter(iso_code=="SWE"|iso_code=='ISL')

what_questions_are = read.csv(file = 'what_questsions_are.csv')
what_answer_codes_mean = read.csv(file = 'what_answer_codes_mean.csv')
country_code_data = read.csv(file = "country_code_data.csv")
mean_data = fromJSON(file="mean_data_per_country.json")
get_full_name <- function(abv) {
  to_ret <- (country_code_data %>% filter(Code==abv))$Name
  return(to_ret)
}

#data_index = fromJSON(file='data_index_orient.json')
data_index = fromJSON(file='data_with_dates.json')
```

# setup variables
```{r}
countries = c('SE','IT','UK','US','AU','DE','ES','MX','JP','KR','CN')
country = 'IT'
quest = 'FinitePool_2'
#questions = c('CanadaQ_2', 'CanadaQ_1', 'Longitude_2', 'FinitePool_2', 'FinitePool_5', 'CanadaQ_3', 'Friends_8', 'Personal_8')
questions = c('CanadaQ_1', 'COVIDeffect_4', 'COVIDeffect_2', 'COVIDeffect_3', 'COVIDeffect_1')
controlling_for_questions = c('COVIDeffect_4', 'COVIDeffect_2' ,'COVIDeffect_3', 'COVIDeffect_1')
country_full_name = (country_code_data %>% filter(Code==country))$Name
```

# helper function
```{r}
put_new_lines <- function(string, num_chars) {
  if (nchar(string) <= num_chars) {
    return(string)
  }
  for (i in num_chars:nchar(string)) {
    if (substr(string,i,i) == " ") {
      first = substr(string, 1, i)
      last = substr(string, i+1, nchar(string))
      if (nchar(last) >= num_chars) {
        last = put_new_lines(last, num_chars)
      }
      new_string <- paste(first, "\n", last)
      return(new_string)
    }
  }
  return(string)
}

normalit<-function(m){
   (m - min(m))/(max(m)-min(m))
 }
```

# setup helper variables
```{r}
question_text <- what_questions_are %>%
  filter(var==quest) %>%
  select('question')

code_text <- what_answer_codes_mean %>%
  filter(var==quest) %>%
  select('code', 'label')

labels = vector()
to_paste <- ""
for (i in 1:max(code_text$code)){
  to_paste = if (i%%2) "" else "\n \n"
  if (i %in% code_text$code) {
    labels <- c(labels, paste(to_paste,put_new_lines(code_text[code_text$code==i,]$label,13)))
  } else {
    labels <- c(labels, i)
  }
}
```

# single histogram plot with question and country
```{r}
to_plot <- data_index[[quest]][[country]] %>%
  as.numeric() %>%
  data.frame()

to_plot$lab <- code_text$label[match(to_plot$.,code_text$code)]

title <- put_new_lines(question_text[question_text != "",], 76)

to_plot%>%
  ggplot(aes(x=.))+
    stat_count() +
    scale_x_discrete(limits=labels,labels=labels) +
    labs(title=title)
```

# setup stringency with all countries
```{r}
question_text <- what_questions_are %>%
  filter(var==quest) %>%
  select('question')

#question_text <- paste("\"", question_text[question_text != "",], sep = "") %>%
#  paste("\" vs stringency per country", sep = "")
#title <- put_new_lines(question_text,76)

title <- put_new_lines('Fear of Covid vs Stringency of country policies',76)

aggregate_data <- data.frame(matrix(ncol = length(questions), nrow = 11))
colnames(aggregate_data) <- questions

for (question in questions) {
  #print(question)
  d1 <- mean_data[[question]] %>%
    data.frame()
  d1 <- data.frame(country=names(d1),Average=t(d1)) %>%
    mutate(country = gsub(".", " ", country, fixed=TRUE)) %>%
    mutate(stringency = as.numeric(mean_data$stringnecy)) %>%
    mutate(Average = normalit(Average))
  d1[question] = normalit(d1$Average)
  
  if (nrow(aggregate_data) == 0) {
    aggregate_data <- d1
  } else {
    aggregate_data <- merge(d1, aggregate_data, all=TRUE)
  }
}

library(data.table)
df <- aggregate_data %>%
  select(-Average, -stringency)
stringency_data <- aggregate_data %>%
  select(country, stringency, 3) %>%
  distinct() %>%
  na.omit()
compressed_data <- setDT(df)[, lapply(.SD, na.omit), by = country] %>%
  mutate(stringency = stringency_data$stringency)
```


# plot question with all countries against stringency
``` {r}
aggregate_data %>%
  ggplot(aes(y=Average, x=stringency, color=country)) +
    geom_point() +
    labs(title=title)
```

# regression with question and stringency with all countries
```{r}
lm_spec <-
    linear_reg() %>% 
    set_engine(engine = 'lm') %>% 
    set_mode('regression')

mod <- fit(lm_spec,
            CanadaQ_1 ~ . -country,
            data = compressed_data)

mod %>%
  tidy()
```

```{r}
full_rec <- recipe(stringency ~ ., data = compressed_data) %>%
    update_role(country, new_role = 'ID') %>% # we want to keep the name of the car model but not as a predictor or outcome
    step_normalize(all_numeric_predictors())# important standardization step for LASSO

set.seed(123)

# Create CV folds
data_cv10 <- vfold_cv(compressed_data, v = 10)

# Lasso Model Spec with tune
lm_lasso_spec_tune <- 
  linear_reg() %>%
  set_args(mixture = 1, penalty = tune()) %>% ## mixture = 1 indicates Lasso
  set_engine(engine = 'glmnet') %>% #note we are using a different engine
  set_mode('regression') 

# Workflow (Recipe + Model)
lasso_wf_tune <- workflow() %>% 
  add_recipe(full_rec) %>% # recipe defined above
  add_model(lm_lasso_spec_tune) 

# Tune Model (trying a variety of values of Lambda penalty)
penalty_grid <- grid_regular(
  penalty(range = c(-3, 1)), #log10 transformed
  levels = 30)

tune_output <- tune_grid( # new function for tuning parameters
  lasso_wf_tune, # workflow
  resamples = data_cv10, # cv folds
  metrics = metric_set(rmse, mae),
  grid = penalty_grid # penalty grid defined above
)

best_se_penalty <- select_by_one_std_err(tune_output, metric = 'mae', desc(penalty)) # choose largest penalty value within 1 se of the lowest cv mae
final_wf_se <- finalize_workflow(lasso_wf_tune, best_se_penalty) # incorporates penalty value to workflow

final_fit_se <- fit(final_wf_se, data = compressed_data)

tidy(final_fit_se)

```

